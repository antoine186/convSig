---
title: "convSig-vignette"
author: "Antoine Yi-Cheng Tian"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{convSig-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

<center><h2> Abstract </h2></center>

This package implements an entirely novel approach for the detection and extraction
of mutational processes that is based on Yun Feng's work 
(convSig project, Oxford University PhD). <br />
Every cancer-affected patient has specific mutational patterns in their genome,
hence detecting, extracting, and characterising such patterns can provide a useful
source of information for the personalisation of cancer treatment.  The methods 
implemented in this package make use of the convolutional filtering techniques found
in computer vision. Our model is centred around the concept of each mutational process 
being represented as a filter, which slides over the entire genome of interest and 
probabilistically induces mutations in sequences that it has a strong rapport with. Our
methods extract and characterise these processes by solving for variables in this 
model using expectation maximisation (either using the ReLU transform or the exponential
transform).

<h1> Data Preparation for Expectation Maximisation </h1>

The EM methods (ReLU and exponential) both require multiple input data that 
conform to a very specific data format, therefore data prepration as outlined here 
will certainly always be a requisite step in our pipeline. <br />
You will invariably start with an ICGC (i.e. International Cancer Genome Consortium) 
mutation file either in the form of a csv file or a tsv file. Please note that there 
currently exists more than one ICGC format (e.g. donor format) and thus it is 
easy to become confused as to which one to use at this stage, however the one 
you should use is the ICGC mutation file format. To find a typical example, please visit
the online ICGC data portal (https://dcc.icgc.org/) and navigate to DCC DATA RELEASE,
 find any project and download any file which contains "simple_somatic_mutation"
 in its name. Or alternatively you can run the below line to load a suitable data input
 example into your global R environment:


```{r setup, include = FALSE}
library(convSig)
```

```{r, eval = FALSE}
loadICGCexample()
````
  
This input ICGC mutation data can either be a path leading to an actual file
on your workstation or data already loaded into your R global environment. In the 
latter case, the data has to either be in the form of a data.frame or a matrix.
This data preparation stage imposes an additional format requirement for 
this data. Namely, the following headers must be present in the input file (Note:
this requirement is easily fulfilled if you have an input file that conforms to
the ICGC format): <br />

* **icgc_sample_id** 
* **chromosome**
* **chromosome_start**
* **chromosome_end**
* **mutated_from_allele** 
* **mutated_to_allele** 
* **assembly_version**
* **sequencing_strategy**

For the first step, you should run the below block of code. It specifies and stores
the path/name of the ICGC input file that you want to work with. Next, it designates
the reference genome file that corresponds to the experiment that you are interested in
and the sequencing strategy as well. <br />
This function call skips all of the X and Y chromosomes (i.e. sex chromosomes),
gathers all of the mutations that pertain to experiments run with your specified
assembly version and sequencing strategy, and applies a base to number conversion
to help filter out invalid types of mutations (e.g. insertions or deletions).

```{r, eval = FALSE}
datapath <- "simple_somatic_mutation.open.COCA-CN.tsv"
mut_file <- icgc2mut(datapath, "GRCh37", "WGS")
```

You should then call the below function on the result produced by icgc2mut(). <br />
In a first instance, it sorts your input in ascending order by chromosome number 
first and then by the mutation chromosome start position. This sorting is required 
as the downstream convolution operation can only scan the reference genome in an 
ordered manner. <br />
In a second instance (optional: depending on user parameter specification), it removes 
all non-single nucleotide polymorphisms as our methods are only valid for single 
nucleotide substitutions. <br />
In a third instance, it removes all duplicate mutations present in the input mutation data.

```{r, eval = FALSE}
cur_mut_file <- icgc_curate(mut_file, remove.nonSNP = TRUE)
```

Subsequently, you should run the mut_count() function. It constructs two essential
count tables: the mutation and the genome background count tables. <br />
The mutation count table is a matrix, which records the frequency of each mutation
types for each sample present in your supplied mutation input data. Each of its rows 
therefore represents a sample and each of its columns represents a distinct mutation
type/possibility. The number of possible mutation types is calculated in accordance
to the length of the mutation signature window (i.e. 3 or 5 bases). The formula used
is: $4^{numbase - 1} \times 2 \times 3$ (where numbase is equal to the length of the window).
We first perform $4^{numbase - 1} \times 2$ because all flanking bases in the window 
(i.e. non-middle bases) have exactly 4 base possibilities and the middle base only
has 2 possibilities. The latter is due to the reverse complementarity nature of
the genome; This is to avoid double counting the mutations that have actually occurred.
We furthermore multiply the intermediate result by 3 here because of the three 
possibilities for the middle base substitution. <br />
The genome background count table is a vector with length equal to the total possible 
number of mutation types as calculated above. It also records the frequency that we could
expect from each mutation under circumstances of equal probability for the occurrence
of such mutations. <br />
Please note that this function call requires you to supply it with the correct 
corresponding reference genome. <br />
The function call can also take a parameter that helps indicate whether you wish 
to construct the count tables for a 3-base long or a 5-base long mutation signature
window. By default, the call is set to run for a 3-base long window.

```{r, eval = FALSE}
assembly <- "Homo_sapiens.GRCh37.dna.primary_assembly.fa"
EMu_prepped <- mut_count(assembly, cur_mut_file, five = FALSE)
```

<h1> Expectation Maximisation Using ReLU or the Exponential Transformation </h1>
<h2> ReLU Transformation </h2>

Our first approach for learning the parameters of interest, subject to a negative 
log-likelihood function as a loss function, via a novel expectation maximisation
technique (EMu), is the ReLU transformation. The parameters whose estimation are sought for 
are a Feature matrix (contains the weights in the mutational filters for their 
corresponding mutational processes), a P matrix (contains the mutational rate of 
each mutational process in each sample), and a mat matrix (contains the probabilities 
for all mutation types; Take T mutating to C as an instance of a mutation type). <br />
The Feature matrix has $(numbase \times 4) - 2$ rows. This number covers and lays out all 
possible bases at each base index in a particular trimer fragment - 4 possible bases
that pertain to a single base index are represented as 4 contiguous rows in the matrix. 
The Feature matrix also has the same number of columns as the number of mutational
processes as indicated by the user. <br />
The P matrix has as many rows as the number of samples present in your input data.
It also contains the same number of columns as the number of mutational processes 
as indicated by the user. <br />
The below function call runs the ReLU transformation. It requires in a first instance
the data output by the previous function call [i.e. mut_count()], a parameter specifying
whether the transformation should consider a 3-base long window vs a 5-base long window, and 
a parameter indicating the number of mutational processes to extract from the input data. <br />

```{r, eval = FALSE}
relu_res <- relu_transform(EMu_prepped, five = TRUE, K = 5)
```

<h2> Exponential Transformation </h2>

The second approach for learning the parameters is the exponential transformation.
The same parameters are sought for, albeit with a different approach, which involves a
different loss function and a different optimisation procedure.

```{r, eval = FALSE}
exp_res <- exp_transform(EMu_prepped, five = TRUE, K = 5)
```

<h2> Differences between both approaches </h2>



