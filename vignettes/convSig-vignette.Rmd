---
title: "convSig-vignette"
author: "Antoine Yi-Cheng Tian"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{convSig-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

<center><h2> Abstract </h2></center>

This package implements an entirely novel approach for the detection and extraction of mutational processes based on Yun Feng's work (convSig project, Oxford University PhD).

Cancer patients have distinct mutational patterns in their genome, hence detecting, extracting, and characterising such patterns can provide a useful source of information for personalized of cancer treatment.  The methods implemented in this package makes use of convolutional filtering techniques found in computer vision. Our model is centred around the concept of each mutational process being represented as a filter, which slides over the entire genome of interest and probabilistically induces mutations in genetic sequences that it has a strong rapport with. Our methods extract and characterise these processes using two variations of
expectation maximisation (i.e. EM).

<h1> Data Preparation for Expectation Maximisation </h1>

<!-- The intro to this section is a bit strange. The user doens't care what problems you had. What you need to do is to give the column names. In markdown you can create a table by:
| Tables        | Are           | Cool  |
| ------------- |:-------------:| -----:|
| col 3 is      | right-aligned | $1600 |

In this format you can give a name for a column and enter a description of what should be in there. use $\cdots$ to indicate more of the same -->

The EM methods (ReLU and exponential transformations) both require multiple input data that conform to specific data format, therefore the data preparation outlined in this section will certainly be a requisite step in most usages of this analysis pipeline.


The earliest upstream data input file is an ICGC (i.e. International Cancer Genome Consortium) mutation file either in the form of a `.csv` file or a `.tsv` file. Please note that there currently exists more than one ICGC format (e.g. donor format), however the one which this pipeline is concerned with is the ICGC mutation file format. To find a typical example, please visit the online ICGC data portal ([dcc.icgc.org](https://dcc.icgc.org/)), navigate to DCC DATA RELEASE, select a project and download any file which contains "simple_somatic_mutation"in its name. Or alternatively you can run the below line to load a suitable data input example into your global R environment:


```{r setup, include = FALSE}
library(convSig)
```

```{r, eval = FALSE}
loadICGCexample()
````

This input ICGC mutation data can be the path to the mutation file on your workstation or data previously loaded into your R global environment (as a `matrix` or `data.frame`). This data preparation stage imposes an additional format requirement for this data. Namely, the following headers must be present in the input file (*Note*: this requirement is easily fulfilled if you have an input file that conforms to the ICGC format):

|`icgc_sample_id`| `chromosome` | `chromosome_start` | `chromosome_end` | `mutated_from_allele` | `mutated_to_allele` | `assembly_version` | `sequencing_strategy` |
|  :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: |
| col 1 | col 2 | col 3 | col 4 | col 5 | col 6 | col 7 | col 8 |

<!-- This is too verbose, and at the same time I am not sure what it does. Start with what the function does and then what the other two variables are. -->

The below block of code designates the reference genome file that corresponds to the relevant experiment and the sequencing strategy used to obtain it.

This function call skips all of the X and Y chromosomes (i.e. sex chromosomes),
gathers all of the mutations that pertain to experiments run with your specified assembly version and sequencing strategy, and applies a base to number conversion to help filter out invalid types of mutations (e.g. insertions or deletions).

```{r, eval = FALSE}
datapath <- "simple_somatic_mutation.open.COCA-CN.tsv"
mut_file <- icgc2mut(datapath, assembly = "GRCh37", Seq = "WGS")
```

Next we use the `icgc_curate()` function, it performs some prerequisite process for further analysis:

1. **Sorting**. The input is sorted in ascending order by chromosome number first and then by the mutation chromosome start position. This is required as the downstream convolution operation can only scan the reference genome in an ordered manner.
2. **Remove non-SNPs**. This is an optional step (using `remove.nonSNP = TRUE`), it removes all non-single nucleotide polymorphisms as our methods are only valid for single nucleotide substitutions.
3. **Remove duplicates**. Finally all duplicate mutations present are removed.

```{r, eval = FALSE}
cur_mut_file <- icgc_curate(mut_file, remove.nonSNP = TRUE)
```

The `mut_count()` function constructs two essential count tables: the mutation and the genome background count tables.

The mutation count table is a matrix, which records the frequency of each mutation type for each sample present in supplied mutation input data. Each of its rows therefore represents a sample and each of its columns represents a distinct mutation type/possibility. The number of possible mutation types is calculated in accordance with the length of the mutation signature window (i.e. 3 or 5 bases only for our methods). The formula used is: $4^{numbase - 1} \times 2 \times 3$ (where numbase is equal to the length of the window). We first perform $4^{numbase - 1} \times 2$ because all flanking bases in the window (i.e. non-middle bases) have exactly 4 base possibilities and the middle base only has 2 possibilities. The latter is due to the reverse complementarity nature of the genome; This is to avoid double counting the mutations that have actually occurred. We furthermore multiply the intermediate result by 3 here because of the three possibilities for the middle base substitution.

The genome background count table is a vector with length equal to the total possible number of mutation types as calculated above. It also records the frequency that we could expect from each mutation under circumstances of equal probability for the occurrence of such mutations.

Please note that this function call requires you to supply it with the correct
corresponding reference genome.

The function call can also take a parameter that helps indicate whether you wish to construct the count tables for a 3-base long or a 5-base long mutation signature window. By default, the call is set to run for a 3-base long window.

```{r, eval = FALSE}
assembly <- "Homo_sapiens.GRCh37.dna.primary_assembly.fa"
EMu_prepped <- mut_count(assembly, cur_mut_file, five = FALSE)
```

<h1> Expectation Maximisation Using ReLU or the Exponential Transformation </h1>

<h2> Expectation Maximisation Parameters and Results </h2>

The ReLU and the Exponential transformations both enable the learning of key parameters via a novel expectation maximization technique (EM) subject to a negative log-likelihood loss function. The parameters whose estimation are sought for are a feature matrix (contains the weights of the mutational filters), a P matrix (contains the mutational rate for each mutational process in each sample), and a mat matrix (contains the probabilities for all mutation types; Take T mutating to C as an instance of a mutation type).

The Feature matrix has $(numbase \times 4) - 2$ rows. This number covers all possible bases at each base index in a particular trimer fragment - 4 possible bases that pertain to a single base index are represented as 4 contiguous rows in the matrix. The Feature matrix also has the same number of columns as the number of mutational processes as indicated by the user.

The P matrix has as many rows as the number of samples present in your input data. It also contains the same number of columns as the number of mutational processes specified by the user.

The mat result is a 3 dimensional matrix with dimensions (2,3,number of mutational processes). The first dimension equals 2 because there are only two distinct original bases possible pre-mutation; That is because of the reverse complementarity nature of the genome. The second dimension equals 3 because there are only three possible mutated bases per
each of the 2 original bases.

<h2> ReLU or Exponential Transformation </h2>

The below function calls require the data output by the previous function call [i.e. mut_count()], a parameter specifying whether the transformation should consider a 3-base long window vs a 5-base long window, and a parameter indicating the number of mutational processes to extract from the pre-processed input data.

```{r, eval = FALSE}
relu_res <- relu_transform(EMu_prepped, five = TRUE, K = 5)
```

```{r, eval = FALSE}
exp_res <- exp_transform(EMu_prepped, five = TRUE, K = 5)
```
